server:
  port: 8080 

management:
  endpoints:
    web:
      exposure:
        include: prometheus,health,info,metrics
  endpoint:
    prometheus:
      enabled: true
    metrics:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    jvm:
      memory:
        enabled: true
      gc:
        enabled: true

spring:
  kafka:
    # Kafka 클러스터 서버 주소 설정
    bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092

    consumer:
      # 그룹 내에서 메시지를 소비할 그룹 ID
      group-id: 'kafka-consumer-group'
      # 처음 시작할 때의 오프셋 위치, earliest는 가장 오래된 메시지부터
      auto-offset-reset: 'earliest'
      # Offset 자동 커밋 비활성화 (수동 커밋 사용)
      enable-auto-commit: false
      # Key/Value의 역직렬화 방식 설정
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # TPS 3000 처리를 위한 최적화 설정
      properties:
        # JSON 설정
        spring.json.trusted.packages: '*' # 모든 패키지의 클래스를 신뢰 (안전한 환경에서만 사용)
        spring.json.value.default.type: java.lang.String
        # Offset 저장소를 Kafka로 명시적 설정
        offset.storage: kafka
        # Consumer Group 상태 저장소를 Kafka로 설정
        group.storage: kafka
        # 배치 크기 (한 번에 가져올 메시지 수)
        max.poll.records: 1000
        # Kafka 4.1 스레드 통합 문제 해결을 위한 명시적 설정
        session.timeout.ms: 30000  # 세션 타임아웃 (30초) - 명시적 설정
        heartbeat.interval.ms: 3000  # 하트비트 간격 (3초) - Kafka 4.1 권장 값
        rebalance.timeout.ms: 60000  # 리밸런싱 타임아웃 (60초) - 충분한 시간 확보
        # 요청 타임아웃 (30초)
        request.timeout.ms: 30000
        # 전체 메시지 최대 크기 (50MB)
        max.poll.interval.ms: 300000
        # 압축 해제 버퍼 크기 (64KB)
        receive.buffer.bytes: 65536
        # 전송 버퍼 크기 (128KB)
        send.buffer.bytes: 131072
        # 재시도 횟수
        retries: 3
        # 재시도 간격 (100ms)
        retry.backoff.ms: 100
        # Kafka 4.1 서버 기반 리밸런싱 설정
        group.protocol: consumer  # 서버 기반 리밸런싱 옵트인 (Kafka 4.1+ 필요)
        # partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor  # 클라이언트 assignor (서버 기반에서는 의미 감소)
        # Kafka 배치 처리 최적화 설정 (TPS 600 처리용)
        fetch.min.bytes: 1024  # 1KB 이상 모이면 즉시 가져오기 (대기 시간 최소화)
        fetch.max.wait.ms: 100  # 최대 100ms 대기 (빠른 응답)
        # 메모리 압박 완화를 위한 설정
        max.partition.fetch.bytes: 10485760  # 10MB

    # 리스너 컨테이너 설정
    listener:
      # 수동 커밋 즉시 커밋 (Kafka 4.1 lag 문제 해결)
      ack-mode: manual_immediate  # acknowledge() 호출 즉시 커밋 요청
      sync-commits: true  # 동기 커밋 필수 - commitSync()로 즉시 반영, 없으면 commitAsync() 사용되어 지연 발생
      # 동시성 설정 (TPS 600 처리용 - 파티션 수의 2배)
      concurrency: 6  # 3개 파티션 × 2
      # 배치 모드 활성화 (여러 메시지 배치 처리)
      type: batch
      # [대안: Single + 작은 배치로 더 미세한 커밋]
      # type: single  # 개별 메시지 처리로 변경 시
      max.poll.records: 200  # 1000 → 200으로 줄여서 더 미세하게 커밋
      # 폴링 간격 (500ms) - 빠른 처리와 배치 크기 균형
      poll-timeout: 500
      # 에러 핸들러 설정
      missing-topics-fatal: false

  # JPA 설정
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        jdbc:
          batch_size: 1000
        order_inserts: true
        order_updates: true
        batch_versioned_data: true

  # 데이터소스 설정 (PostgreSQL)
  datasource:
    url: jdbc:postgresql://192.168.211.138:5432/kafka_db
    driver-class-name: org.postgresql.Driver
    username: postgres
    password: postgres
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000

# 로깅 설정
logging:
  level:
    apache.kafkaconsumer: INFO
    org.springframework.kafka: WARN
    org.hibernate.SQL: WARN
    org.hibernate.type.descriptor.sql.BasicBinder: WARN
    # GC 로그 설정
    gc: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"


